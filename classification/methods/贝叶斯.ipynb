{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###先验概率\n",
    "事件A发生的概率记为P(A)，这个先验概率值可以用相对频率来近似。根据大数定律，当训练集包含足够多的独立同分布样本时P(A)可通过样本出现的频率来估算。\n",
    "###联合概率\n",
    "事件A和事件B同时发生的概率，记为P(A,B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "。\n",
    "若事件A和事件B相互独立，则：\n",
    "      P(A,B) = P(A) ×P(B)\n",
    "###条件概率(后验概率)\n",
    "在事件A发生的条件下，事件B发生的概率，记为P(B|A)，或PA(B).\n",
    "   P(B|A) = P(A,B)/P(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有两个各装了100个球的箱子，甲箱子中有70个红球，30个绿球，乙箱子中有30个红球，70个绿球。假设随机选择其中一个箱子，从中拿出一个球记下球色再放回原箱子，如此重复12次，记录得到8次红球，4次绿球。问题来了，你认为被选择的箱子是甲箱子的概率有多大？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择的箱子是甲箱子的概率有多大？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#第一个为身高，第二个值为体重(kg),第三个为性别,1为男，2为女\n",
    "x_train = [[160, 60, 1], [155, 80, 1], [178, 53, 2], [158, 53, 2], [166, 45, 2], [170, 50, 2], [156, 56, 2],\n",
    "           [166, 50, 1], [175, 55, 1], [188, 68, 1], [159, 41, 2], [166, 70, 1], [175, 85, 1], [188, 98, 1],\n",
    "           [159, 61, 2]]\n",
    "y_train = [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1]\n",
    "x_test = [[166, 45, 2], [172, 52, 1], [156, 60, 1], [150, 70, 2], [166, 60, 1]]\n",
    "#实现贝叶斯算法\n",
    "\n",
    "def loadDataSet():\n",
    "    postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'hime'],\n",
    "                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0, 1, 0, 1, 0, 1]\n",
    "    return postingList, classVec\n",
    "\n",
    "\n",
    "# 构建词系列\n",
    "def getSquenceSet(data):\n",
    "    dlen = len(data)\n",
    "    squence = set([])\n",
    "    for i in range(dlen):\n",
    "        squence = squence | set(data[i])\n",
    "    return list(squence)\n",
    "postingList, classVec = loadDataSet()\n",
    "s = getSquenceSet(postingList)\n",
    "# print(s)\n",
    "\n",
    "\n",
    "#将字符传转换为一个向量\n",
    "def word2vec(sequence, data):\n",
    "    # data: 是整个输入列\n",
    "    dlist = [0] * len(sequence)\n",
    "    for ldata in data:\n",
    "        if ldata in sequence:\n",
    "            dlist[sequence.index(ldata)] = 1\n",
    "        else:\n",
    "            print(\"no word match!\")\n",
    "    return dlist\n",
    "\n",
    "\n",
    "\n",
    "def getPre(postinglis, classVec):\n",
    "    dlist = list([])\n",
    "    sequence = getSquenceSet(postingList)\n",
    "\n",
    "    # 获得总的词个数\n",
    "    for clodata in postingList:\n",
    "        dlist.append(word2vec(sequence, clodata))\n",
    "\n",
    "    pVec = np.ones(len(sequence))  #为1的词个数\n",
    "    pNum = 2  #为1的数量\n",
    "    nVec = np.ones(len(sequence))  #为0的初始个数\n",
    "    nNum = 2\n",
    "    for i in classVec:\n",
    "        if i == 1:\n",
    "            pVec += dlist[i]\n",
    "            pNum += 1\n",
    "        else:\n",
    "            nVec += dlist[i]\n",
    "            nNum += 1\n",
    "    pVec = np.log(pVec / pNum)\n",
    "    nVec = np.log(nVec / nNum)\n",
    "    pp = np.sum(classVec) / float(len(classVec))\n",
    "    return pVec, nVec, pp\n",
    "pVec, nVec, pp = getPre(postingList, classVec)\n",
    "pVec, nVec, pp\n",
    "\n",
    "\n",
    "def classNB(testData, pVec, nVec, pp):\n",
    "    p = np.sum(testData * pVec) + np.log(pp)\n",
    "    n = np.sum(testData * nVec) + np.log(1.0 - pp)\n",
    "    if p > n:\n",
    "        print(\"1\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"0\")\n",
    "        return 0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testingNB():\n",
    "    listOPosts, listClasses =  loadDataSet()   # 加载数据\n",
    "    sequence = getSquenceSet(postingList)\n",
    "    p0V, p1V, pAb = getPre(listOPosts, listClasses) # 计算先验概率\n",
    "    testEntry = ['love', 'my', 'dalmation']   # 测试文档1\n",
    "    thisDoc = np.array(word2vec(sequence, testEntry))\n",
    "    print(testEntry, 'classified as :', classNB(thisDoc, p0V, p1V, pAb))\n",
    "    testEntry = ['stupid', 'garbage', 'stupid'] # 测试文档2\n",
    "    thisDoc = np.array(word2vec(sequence, testEntry))\n",
    "    print(testEntry, 'classified as : ', classNB(thisDoc, p0V, p1V, pAb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['love', 'my', 'dalmation'] classified as : 0\n",
      "1\n",
      "['stupid', 'garbage', 'stupid'] classified as :  1\n"
     ]
    }
   ],
   "source": [
    "testingNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
